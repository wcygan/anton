---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: hugs-gemma
spec:
  interval: 1h
  chart:
    spec:
      chart: hugs
      # TODO: Check for the latest version at https://github.com/huggingface/hugs-helm-chart
      version: "0.0.4"  # Latest version from https://github.com/huggingface/hugs-helm-chart
      sourceRef:
        kind: HelmRepository
        name: hugs
        namespace: flux-system
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
      remediateLastFailure: true
  values:
    image:
      repository: hfhugs
      name: unsloth-gemma-3-4b-it-GGUF
      tag: Q4_K_XL  # Using tag for specific GGUF quantization

    # Resource configuration
    resources:
      requests:
        cpu: "2"
        memory: "8Gi"
      limits:
        cpu: "4"
        memory: "16Gi"
        # Uncomment if you have GPU available
        # nvidia.com/gpu: 1

    # Service configuration
    service:
      type: ClusterIP
      port: 8080

    # Optionally expose via ingress
    # ingress:
    #   enabled: true
    #   className: internal
    #   annotations:
    #     cert-manager.io/cluster-issuer: "letsencrypt-production"
    #   hosts:
    #     - host: "gemma.${SECRET_DOMAIN}"
    #       paths:
    #         - path: /
    #           pathType: Prefix
    #   tls:
    #     - secretName: gemma-tls
    #       hosts:
    #         - "gemma.${SECRET_DOMAIN}"

    # Environment variables if needed
    # env:
    #   - name: HUGGING_FACE_HUB_TOKEN
    #     valueFrom:
    #       secretKeyRef:
    #         name: hugs-secrets
    #         key: hf-token