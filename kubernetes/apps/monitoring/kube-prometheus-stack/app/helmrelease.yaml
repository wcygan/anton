apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  interval: 15m
  chart:
    spec:
      chart: kube-prometheus-stack
      version: "72.9.1"
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
      interval: 5m
  releaseName: kube-prometheus-stack
  targetNamespace: monitoring
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
      remediateLastFailure: true
    cleanupOnFail: true
  # Default values are generally good for a start.
  # You can customize values here as needed, for example:
  values:
    # Resource limits for all components
    prometheusOperator:
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          cpu: 500m
          memory: 512Mi

    prometheus:
      enabled: true
      prometheusSpec:
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 2
            memory: 4Gi

    alertmanager:
      enabled: true
      alertmanagerSpec:
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi

    grafana:
      enabled: true
      # Default admin password is "prom-operator"
      # Consider managing this via 1Password/ESO for production
      adminPassword: "prom-operator"
      additionalDataSources:
        - name: Loki
          type: loki
          access: proxy
          url: http://loki-gateway.monitoring.svc.cluster.local
          jsonData:
            timeout: 120  # Increased timeout for better reliability
            maxLines: 5000  # Increased for richer dashboards
            maxConcurrentShardRequests: 32  # Enable concurrent requests
      resources:
        requests:
          cpu: 200m  # Increased for better responsiveness
          memory: 512Mi  # Increased for dashboard caching
        limits:
          cpu: 1000m  # Doubled for faster dashboard loading
          memory: 2Gi  # Doubled for better caching

    kubeStateMetrics:
      enabled: true
      resources:
        requests:
          cpu: 50m
          memory: 64Mi
        limits:
          cpu: 200m
          memory: 256Mi

    nodeExporter:
      enabled: true
      resources:
        requests:
          cpu: 10m
          memory: 32Mi
        limits:
          cpu: 100m
          memory: 128Mi
