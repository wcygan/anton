# Temporary script to fix Ceph PG warnings
# This will be applied manually and then removed

---
# Step 1: Reduce PGs for the erasure-coded pool
apiVersion: v1
kind: ConfigMap
metadata:
  name: ceph-pg-fix-script
  namespace: storage
data:
  fix-pgs.sh: |
    #!/bin/bash
    set -e
    
    echo "=== Ceph PG Fix Script ==="
    echo "Current PG status:"
    ceph pg stat
    echo ""
    
    # Step 1: Reduce PGs for erasure-coded pool
    echo "Step 1: Reducing PGs for ceph-objectstore.rgw.buckets.data from 256 to 64..."
    ceph osd pool set ceph-objectstore.rgw.buckets.data pg_num 64
    sleep 5
    ceph osd pool set ceph-objectstore.rgw.buckets.data pgp_num 64
    
    # Step 2: Set pg_num_max to prevent autoscaler from increasing PGs too much
    echo ""
    echo "Step 2: Setting pg_num_max for large pools..."
    ceph osd pool set ceph-objectstore.rgw.buckets.data pg_num_max 64
    ceph osd pool set replicapool pg_num_max 64
    ceph osd pool set ceph-filesystem-data0 pg_num_max 64
    
    # Step 3: Clean up orphaned pools (if empty)
    echo ""
    echo "Step 3: Checking orphaned pools..."
    
    # List pools that might be orphaned
    for pool in ceph-objectstore.rgw.control ceph-objectstore.rgw.meta ceph-objectstore.rgw.log \
                ceph-objectstore.rgw.buckets.index ceph-objectstore.rgw.buckets.non-ec \
                ceph-objectstore.rgw.otp default.rgw.log default.rgw.control default.rgw.meta; do
      objects=$(rados df | grep "^$pool " | awk '{print $3}')
      if [ "$objects" = "0" ] || [ -z "$objects" ]; then
        echo "Pool $pool has no objects and could be deleted"
      else
        echo "Pool $pool has $objects objects - keeping"
      fi
    done
    
    echo ""
    echo "Step 4: Wait for PG rebalancing..."
    sleep 10
    
    echo ""
    echo "Final PG status:"
    ceph pg stat
    ceph osd pool autoscale-status
    
    echo ""
    echo "Health check:"
    ceph health detail